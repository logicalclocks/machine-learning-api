{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hopsworks Model Registry # HSML is the library to interact with the Hopsworks Model Registry. The library makes it easy to export and manage models. The library automatically configures itself based on the environment it is run. However, to connect from an external Python environment additional connection information, such as host and port, is required. For more information about the setup from external environments, see the setup section. Getting Started On Hopsworks # Instantiate a connection and get the project model registry handle import hsml # Create a connection connection = hsml . connection () # Get the model registry handle for the project's model registry mr = connection . get_model_registry () Create a new model mnist_model_meta = mr . tensorflow . create_model ( name = \"mnist\" , version = 1 , metrics = { \"accuracy\" : 0.94 }, description = \"mnist model description\" ) mnist_model_meta . save ( \"/tmp/model_directory\" ) Download a model mnist_model_meta = mr . get_model ( \"name\" , version = 1 ) model_path = mnist_model_meta . download () Delete a model mnist_model_meta . delete () Get best performing model mnist_model_meta = mr . get_best_model ( 'mnist' , 'accuracy' , 'max' ) You can find more examples on how to use the library in examples.hopsworks.ai . Documentation # Documentation is available at Hopsworks Model Registry Documentation . Issues # For general questions about the usage of Hopsworks Machine Learning please open a topic on Hopsworks Community . Please report any issue using Github issue tracking . Contributing # If you would like to contribute to this library, please see the Contribution Guidelines .","title":"Introduction"},{"location":"#hopsworks-model-registry","text":"HSML is the library to interact with the Hopsworks Model Registry. The library makes it easy to export and manage models. The library automatically configures itself based on the environment it is run. However, to connect from an external Python environment additional connection information, such as host and port, is required. For more information about the setup from external environments, see the setup section.","title":"Hopsworks Model Registry"},{"location":"#getting-started-on-hopsworks","text":"Instantiate a connection and get the project model registry handle import hsml # Create a connection connection = hsml . connection () # Get the model registry handle for the project's model registry mr = connection . get_model_registry () Create a new model mnist_model_meta = mr . tensorflow . create_model ( name = \"mnist\" , version = 1 , metrics = { \"accuracy\" : 0.94 }, description = \"mnist model description\" ) mnist_model_meta . save ( \"/tmp/model_directory\" ) Download a model mnist_model_meta = mr . get_model ( \"name\" , version = 1 ) model_path = mnist_model_meta . download () Delete a model mnist_model_meta . delete () Get best performing model mnist_model_meta = mr . get_best_model ( 'mnist' , 'accuracy' , 'max' ) You can find more examples on how to use the library in examples.hopsworks.ai .","title":"Getting Started On Hopsworks"},{"location":"#documentation","text":"Documentation is available at Hopsworks Model Registry Documentation .","title":"Documentation"},{"location":"#issues","text":"For general questions about the usage of Hopsworks Machine Learning please open a topic on Hopsworks Community . Please report any issue using Github issue tracking .","title":"Issues"},{"location":"#contributing","text":"If you would like to contribute to this library, please see the Contribution Guidelines .","title":"Contributing"},{"location":"CONTRIBUTING/","text":"Python development setup # Fork and clone the repository Create a new Python environment with your favourite environment manager, e.g. virtualenv or conda Install repository in editable mode with development dependencies: cd python pip install -e \".[dev]\" Install pre-commit and then activate its hooks. pre-commit is a framework for managing and maintaining multi-language pre-commit hooks. The Model Registry uses pre-commit to ensure code-style and code formatting through black and flake8 . Run the following commands from the python directory: cd python pip install --user pre-commit pre-commit install Afterwards, pre-commit will run whenever you commit. To run formatting and code-style separately, you can configure your IDE, such as VSCode, to use black and flake8, or run them via the command line: cd python flake8 hsml black hsml Python documentation # We follow a few best practices for writing the Python documentation: Use the google docstring style: \"\"\"[One Line Summary] [Extended Summary] [!!! example import xyz ] # Arguments arg1: Type[, optional]. Description[, defaults to `default`] arg2: Type[, optional]. Description[, defaults to `default`] # Returns Type. Description. # Raises Exception. Description. \"\"\" If Python 3 type annotations are used, they are inserted automatically. Model registry entity engine methods (e.g. ModelEngine etc.) only require a single line docstring. REST Api implementations (e.g. ModelApi etc.) should be fully documented with docstrings without defaults. Public Api such as metadata objects should be fully documented with defaults. Setup and Build Documentation # We use mkdocs together with mike ( for versioning ) to build the documentation and a plugin called keras-autodoc to auto generate Python API documentation from docstrings. Background about mike : mike builds the documentation and commits it as a new directory to the gh-pages branch. Each directory corresponds to one version of the documentation. Additionally, mike maintains a json in the root of gh-pages with the mappings of versions/aliases for each of the directories available. With aliases you can define extra names like dev or latest , to indicate stable and unstable releases. Currently we are using our own version of keras-autodoc pip install git+https://github.com/logicalclocks/keras-autodoc@split-tags-properties Install HSML with docs extras: pip install -e . [ dev,docs ] To build the docs, first run the auto doc script: cd .. python auto_doc.py Option 1: Build only current version of docs # Either build the docs, or serve them dynamically: Note: Links and pictures might not resolve properly later on when checking with this build. The reason for that is that the docs are deployed with versioning on docs.hopsworks.ai and therefore another level is added to all paths, e.g. docs.hopsworks.ai/[version-or-alias] . Using relative links should not be affected by this, however, building the docs with version (Option 2) is recommended. mkdocs build # or mkdocs serve Option 2 (Preferred): Build multi-version doc with mike # Versioning on docs.hopsworks.ai # On docs.hopsworks.ai we implement the following versioning scheme: current master branches (e.g. of hsml corresponding to master of Hopsworks): rendered as current Hopsworks snapshot version, e.g. 2.2.0-SNAPSHOT [dev] , where dev is an alias to indicate that this is an unstable version. the latest release: rendered with full current version, e.g. 2.1.5 [latest] with latest alias to indicate that this is the latest stable release. previous stable releases: rendered without alias, e.g. 2.1.4 . Build Instructions # For this you can either checkout and make a local copy of the upstream/gh-pages branch, where mike maintains the current state of docs.hopsworks.ai, or just build documentation for the branch you are updating: Building one branch: Checkout your dev branch with modified docs: git checkout [ dev-branch ] Generate API docs if necessary: python auto_doc.py Build docs with a version and alias mike deploy [ version ] [ alias ] --update-alias # for example, if you are updating documentation to be merged to master, # which will become the new SNAPSHOT version: mike deploy 2 .2.0-SNAPSHOT dev --update-alias # if you are updating docs of the latest stable release branch mike deploy [ version ] latest --update-alias # if you are updating docs of a previous stable release branch mike deploy [ version ] If no gh-pages branch existed in your local repository, this will have created it. Important : If no previous docs were built, you will have to choose a version as default to be loaded as index, as follows mike set-default [ version-or-alias ] You can now checkout the gh-pages branch and serve: git checkout gh-pages mike serve You can also list all available versions/aliases: mike list Delete and reset your local gh-pages branch: mike delete --all # or delete single version mike delete [ version-or-alias ] Adding new API documentation # To add new documentation for APIs, you need to add information about the method/class to document to the auto_doc.py script: PAGES = { \"connection.md\" : [ \"hsml.connection.Connection.connection\" , \"hsml.connection.Connection.setup_databricks\" , ] \"new_template.md\" : [ \"module\" , \"xyz.asd\" ] } Now you can add a template markdown file to the docs/templates directory with the name you specified in the auto-doc script. The new_template.md file should contain a tag to identify the place at which the API documentation should be inserted: ## The XYZ package {{module}} Some extra content here. !!! example ```python import xyz ``` {{xyz.asd}} Finally, run the auto_doc.py script, as decribed above, to update the documentation. For information about Markdown syntax and possible Admonitions/Highlighting etc. see the Material for Mkdocs themes reference documentation .","title":"Contributing"},{"location":"CONTRIBUTING/#python-development-setup","text":"Fork and clone the repository Create a new Python environment with your favourite environment manager, e.g. virtualenv or conda Install repository in editable mode with development dependencies: cd python pip install -e \".[dev]\" Install pre-commit and then activate its hooks. pre-commit is a framework for managing and maintaining multi-language pre-commit hooks. The Model Registry uses pre-commit to ensure code-style and code formatting through black and flake8 . Run the following commands from the python directory: cd python pip install --user pre-commit pre-commit install Afterwards, pre-commit will run whenever you commit. To run formatting and code-style separately, you can configure your IDE, such as VSCode, to use black and flake8, or run them via the command line: cd python flake8 hsml black hsml","title":"Python development setup"},{"location":"CONTRIBUTING/#python-documentation","text":"We follow a few best practices for writing the Python documentation: Use the google docstring style: \"\"\"[One Line Summary] [Extended Summary] [!!! example import xyz ] # Arguments arg1: Type[, optional]. Description[, defaults to `default`] arg2: Type[, optional]. Description[, defaults to `default`] # Returns Type. Description. # Raises Exception. Description. \"\"\" If Python 3 type annotations are used, they are inserted automatically. Model registry entity engine methods (e.g. ModelEngine etc.) only require a single line docstring. REST Api implementations (e.g. ModelApi etc.) should be fully documented with docstrings without defaults. Public Api such as metadata objects should be fully documented with defaults.","title":"Python documentation"},{"location":"CONTRIBUTING/#setup-and-build-documentation","text":"We use mkdocs together with mike ( for versioning ) to build the documentation and a plugin called keras-autodoc to auto generate Python API documentation from docstrings. Background about mike : mike builds the documentation and commits it as a new directory to the gh-pages branch. Each directory corresponds to one version of the documentation. Additionally, mike maintains a json in the root of gh-pages with the mappings of versions/aliases for each of the directories available. With aliases you can define extra names like dev or latest , to indicate stable and unstable releases. Currently we are using our own version of keras-autodoc pip install git+https://github.com/logicalclocks/keras-autodoc@split-tags-properties Install HSML with docs extras: pip install -e . [ dev,docs ] To build the docs, first run the auto doc script: cd .. python auto_doc.py","title":"Setup and Build Documentation"},{"location":"CONTRIBUTING/#option-1-build-only-current-version-of-docs","text":"Either build the docs, or serve them dynamically: Note: Links and pictures might not resolve properly later on when checking with this build. The reason for that is that the docs are deployed with versioning on docs.hopsworks.ai and therefore another level is added to all paths, e.g. docs.hopsworks.ai/[version-or-alias] . Using relative links should not be affected by this, however, building the docs with version (Option 2) is recommended. mkdocs build # or mkdocs serve","title":"Option 1: Build only current version of docs"},{"location":"CONTRIBUTING/#option-2-preferred-build-multi-version-doc-with-mike","text":"","title":"Option 2 (Preferred): Build multi-version doc with mike"},{"location":"CONTRIBUTING/#versioning-on-docshopsworksai","text":"On docs.hopsworks.ai we implement the following versioning scheme: current master branches (e.g. of hsml corresponding to master of Hopsworks): rendered as current Hopsworks snapshot version, e.g. 2.2.0-SNAPSHOT [dev] , where dev is an alias to indicate that this is an unstable version. the latest release: rendered with full current version, e.g. 2.1.5 [latest] with latest alias to indicate that this is the latest stable release. previous stable releases: rendered without alias, e.g. 2.1.4 .","title":"Versioning on docs.hopsworks.ai"},{"location":"CONTRIBUTING/#build-instructions","text":"For this you can either checkout and make a local copy of the upstream/gh-pages branch, where mike maintains the current state of docs.hopsworks.ai, or just build documentation for the branch you are updating: Building one branch: Checkout your dev branch with modified docs: git checkout [ dev-branch ] Generate API docs if necessary: python auto_doc.py Build docs with a version and alias mike deploy [ version ] [ alias ] --update-alias # for example, if you are updating documentation to be merged to master, # which will become the new SNAPSHOT version: mike deploy 2 .2.0-SNAPSHOT dev --update-alias # if you are updating docs of the latest stable release branch mike deploy [ version ] latest --update-alias # if you are updating docs of a previous stable release branch mike deploy [ version ] If no gh-pages branch existed in your local repository, this will have created it. Important : If no previous docs were built, you will have to choose a version as default to be loaded as index, as follows mike set-default [ version-or-alias ] You can now checkout the gh-pages branch and serve: git checkout gh-pages mike serve You can also list all available versions/aliases: mike list Delete and reset your local gh-pages branch: mike delete --all # or delete single version mike delete [ version-or-alias ]","title":"Build Instructions"},{"location":"CONTRIBUTING/#adding-new-api-documentation","text":"To add new documentation for APIs, you need to add information about the method/class to document to the auto_doc.py script: PAGES = { \"connection.md\" : [ \"hsml.connection.Connection.connection\" , \"hsml.connection.Connection.setup_databricks\" , ] \"new_template.md\" : [ \"module\" , \"xyz.asd\" ] } Now you can add a template markdown file to the docs/templates directory with the name you specified in the auto-doc script. The new_template.md file should contain a tag to identify the place at which the API documentation should be inserted: ## The XYZ package {{module}} Some extra content here. !!! example ```python import xyz ``` {{xyz.asd}} Finally, run the auto_doc.py script, as decribed above, to update the documentation. For information about Markdown syntax and possible Admonitions/Highlighting etc. see the Material for Mkdocs themes reference documentation .","title":"Adding new API documentation"},{"location":"quickstart/","text":"Quickstart Guide # The Hopsworks model registry is a centralized repository, within an organization, to manage machine learning models. A model is the product of training a machine learning algorithm with training data. It could be an image classifier used to detect objects in an image, such as for example detecting cancer in an MRI scan. In this Quickstart Guide we are going to focus on how data scientists can create models and publish them to the model registry to make them available for further development and serving. HSML library # The Hopsworks model registry library is called hsml ( H opswork s M achine L earning). The library is Apache V2 licensed and available here . The library currently comes with a Python SDK. If you want to connect to the Model Registry from outside Hopsworks, see our integration guides . The library is build around metadata-objects, representing entities within the Model Registry. You can modify metadata by changing it in the metadata-objects and subsequently persisting it to the Model Registry. In fact, the Model Registry itself is also represented by an object. Furthermore, these objects have methods to save model artifacts along with the entities in the model registry. Guide Notebooks # This guide is based on a series of notebooks , which is available in the Deep Learning Demo Tour Project on Hopsworks. Connection, Project and Model Registry # The first step is to establish a connection with your Hopsworks Model Registry instance and retrieve the object that represents the Model Registry you'll be working with. By default connection.get_model_registry() returns the model registry of the project you are working with. However, it accepts also a project name as parameter to select a different model registry. Python import hsml # Create a connection connection = hsml . connection () # Get the model registry handle for the project's model registry mr = connection . get_model_registry () Models # Assuming you have done some model training, and exported a model to a directory on a local file path, the model artifacts and additional metadata can now be saved to the Model Registry. See the example notebooks . Creation # Create a model named mnist . As you can see, you have the possibility to set parameters for the Model, such as the version number, or metrics which is set to attach model training metrics on the model. The Model Guide guides through the full configuration of Models. Python mnist_model_meta = mr . tensorflow . create_model ( name = \"mnist\" , version = 1 , metrics = { \"accuracy\" : 0.94 }, description = \"mnist model description\" ) Up to this point we have just created the metadata object representing the model. However, we haven't saved the model in the model registry yet. To do so, we can call the method save on the metadata object created in the cell above. The save method takes a single parameter which is the path to the directory on the local filesystem which contains all your model artifacts. Python mnist_model_meta . save ( \"/tmp/model_directory\" ) Retrieval # If there were models previously created in your Model Registry, or you want to pick up where you left off before, you can retrieve and read models in a similar fashion as creating them: Using the Model Registry object, you can retrieve handles to the entities, such as models, in the Model Registry. By default, this will return the first version of an entity, if you want a more recent version, you need to specify the version. Python mnist_model_meta = mr . get_model ( 'mnist' , version = 1 ) # Download the model model_download_path = mnist_model_meta . download () # Load the model tf . saved_model . load ( model_download_path ) To seamlessly combine HSML with model serving components the library makes it simple to also query for the best performing model. In this instance, we get the best model version by querying for the model version with the highest accuracy metric attached. Python mnist_model_meta = mr . get_best_model ( 'mnist' , 'accuracy' , 'max' )","title":"Quickstart"},{"location":"quickstart/#quickstart-guide","text":"The Hopsworks model registry is a centralized repository, within an organization, to manage machine learning models. A model is the product of training a machine learning algorithm with training data. It could be an image classifier used to detect objects in an image, such as for example detecting cancer in an MRI scan. In this Quickstart Guide we are going to focus on how data scientists can create models and publish them to the model registry to make them available for further development and serving.","title":"Quickstart Guide"},{"location":"quickstart/#hsml-library","text":"The Hopsworks model registry library is called hsml ( H opswork s M achine L earning). The library is Apache V2 licensed and available here . The library currently comes with a Python SDK. If you want to connect to the Model Registry from outside Hopsworks, see our integration guides . The library is build around metadata-objects, representing entities within the Model Registry. You can modify metadata by changing it in the metadata-objects and subsequently persisting it to the Model Registry. In fact, the Model Registry itself is also represented by an object. Furthermore, these objects have methods to save model artifacts along with the entities in the model registry.","title":"HSML library"},{"location":"quickstart/#guide-notebooks","text":"This guide is based on a series of notebooks , which is available in the Deep Learning Demo Tour Project on Hopsworks.","title":"Guide Notebooks"},{"location":"quickstart/#connection-project-and-model-registry","text":"The first step is to establish a connection with your Hopsworks Model Registry instance and retrieve the object that represents the Model Registry you'll be working with. By default connection.get_model_registry() returns the model registry of the project you are working with. However, it accepts also a project name as parameter to select a different model registry. Python import hsml # Create a connection connection = hsml . connection () # Get the model registry handle for the project's model registry mr = connection . get_model_registry ()","title":"Connection, Project and Model Registry"},{"location":"quickstart/#models","text":"Assuming you have done some model training, and exported a model to a directory on a local file path, the model artifacts and additional metadata can now be saved to the Model Registry. See the example notebooks .","title":"Models"},{"location":"quickstart/#creation","text":"Create a model named mnist . As you can see, you have the possibility to set parameters for the Model, such as the version number, or metrics which is set to attach model training metrics on the model. The Model Guide guides through the full configuration of Models. Python mnist_model_meta = mr . tensorflow . create_model ( name = \"mnist\" , version = 1 , metrics = { \"accuracy\" : 0.94 }, description = \"mnist model description\" ) Up to this point we have just created the metadata object representing the model. However, we haven't saved the model in the model registry yet. To do so, we can call the method save on the metadata object created in the cell above. The save method takes a single parameter which is the path to the directory on the local filesystem which contains all your model artifacts. Python mnist_model_meta . save ( \"/tmp/model_directory\" )","title":"Creation"},{"location":"quickstart/#retrieval","text":"If there were models previously created in your Model Registry, or you want to pick up where you left off before, you can retrieve and read models in a similar fashion as creating them: Using the Model Registry object, you can retrieve handles to the entities, such as models, in the Model Registry. By default, this will return the first version of an entity, if you want a more recent version, you need to specify the version. Python mnist_model_meta = mr . get_model ( 'mnist' , version = 1 ) # Download the model model_download_path = mnist_model_meta . download () # Load the model tf . saved_model . load ( model_download_path ) To seamlessly combine HSML with model serving components the library makes it simple to also query for the best performing model. In this instance, we get the best model version by querying for the model version with the highest accuracy metric attached. Python mnist_model_meta = mr . get_best_model ( 'mnist' , 'accuracy' , 'max' )","title":"Retrieval"},{"location":"setup/","text":"Hopsworks # If you are using Spark or Python within Hopsworks, there is no further configuration required. Head over to the Getting Started Guide . External Python environment (Local) # Connecting to the Model Registry from any Python environment, such as your local environment, requires setting up a Model Registry API Key and installing the HSML Python client library. The Python integration guide explains step by step how to connect to the Model Registry from any Python environment. AWS Sagemaker # Connecting to the Model Registry from SageMaker requires setting up a Model Registry API Key for SageMaker and installing the HSML Python client library on SageMaker. The AWS SageMaker integration guide explains step by step how to connect to the Model Registry from SageMaker.","title":"Overview"},{"location":"setup/#hopsworks","text":"If you are using Spark or Python within Hopsworks, there is no further configuration required. Head over to the Getting Started Guide .","title":"Hopsworks"},{"location":"setup/#external-python-environment-local","text":"Connecting to the Model Registry from any Python environment, such as your local environment, requires setting up a Model Registry API Key and installing the HSML Python client library. The Python integration guide explains step by step how to connect to the Model Registry from any Python environment.","title":"External Python environment (Local)"},{"location":"setup/#aws-sagemaker","text":"Connecting to the Model Registry from SageMaker requires setting up a Model Registry API Key for SageMaker and installing the HSML Python client library on SageMaker. The AWS SageMaker integration guide explains step by step how to connect to the Model Registry from SageMaker.","title":"AWS Sagemaker"},{"location":"generated/model/","text":"Model # A Model is an artifact that has been trained to recognize certain patterns. In addition to the artifact itself, a great deal of information is needed to describe it. The Model abstraction lets you save the model artifact along with metadata. Versioning # Models can be versioned. When a new Model is published to the Model Registry it is automatically incremented. Creation # [source] create_model # hsml . model_registry . ModelRegistry . tensorflow . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a TensorFlow model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. For more frameworks see Model API Retrieval # [source] get_model # ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. Properties # [source] created # Creation date of the model. [source] description # Description of the model. [source] environment # Input example of the model. [source] experiment_id # Experiment Id of the model. [source] experiment_project_name # experiment_project_name of the model. [source] framework # framework of the model. [source] id # Id of the model. [source] input_example # input_example of the model. [source] model_path # path of the model with version folder omitted. Resolves to /Projects/{project_name}/Models/{name} [source] model_registry_id # model_registry_id of the model. [source] model_schema # model schema of the model. [source] name # Name of the model. [source] program # Executable used to export the model. [source] project_name # project_name of the model. [source] shared_registry_project_name # shared_registry_project_name of the model. [source] training_dataset # training_dataset of the model. [source] training_metrics # Training metrics of the model. [source] user # user of the model. [source] version # Version of the model. [source] version_path # path of the model including version folder. Resolves to /Projects/{project_name}/Models/{name}/{version} Methods # [source] delete # Model . delete () Delete the model Potentially dangerous operation This operation drops all metadata associated with this version of the model and deletes the model files. Raises RestAPIError . [source] delete_tag # Model . delete_tag ( name ) Delete a tag attached to a model. Arguments name str : Name of the tag to be removed. Raises RestAPIError in case the backend fails to delete the tag. [source] deploy # Model . deploy ( name = None , artifact_version = \"CREATE\" , predictor_config = None , transformer_config = None ) Deploy the model [source] download # Model . download () Download the model files to a local folder. [source] get_tag # Model . get_tag ( name ) Get the tags of a model. Arguments name str : Name of the tag to get. Returns tag value Raises RestAPIError in case the backend fails to retrieve the tag. [source] get_tags # Model . get_tags () Retrieves all tags attached to a model. Returns Dict[str, obj] of tags. Raises RestAPIError in case the backend fails to retrieve the tags. [source] save # Model . save ( model_path , await_registration = 480 ) Persist this model including model files and metadata to the model registry. [source] set_tag # Model . set_tag ( name , value ) Attach a tag to a model. A tag consists of a pair. Tag names are unique identifiers across the whole cluster. The value of a tag can be any valid json - primitives, arrays or json objects. Arguments name str : Name of the tag to be added. value Union[str, dict] : Value of the tag to be added. Raises RestAPIError in case the backend fails to add the tag.","title":"Model"},{"location":"generated/model/#model","text":"A Model is an artifact that has been trained to recognize certain patterns. In addition to the artifact itself, a great deal of information is needed to describe it. The Model abstraction lets you save the model artifact along with metadata.","title":"Model"},{"location":"generated/model/#versioning","text":"Models can be versioned. When a new Model is published to the Model Registry it is automatically incremented.","title":"Versioning"},{"location":"generated/model/#creation","text":"[source]","title":"Creation"},{"location":"generated/model/#create_model","text":"hsml . model_registry . ModelRegistry . tensorflow . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a TensorFlow model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. For more frameworks see Model API","title":"create_model"},{"location":"generated/model/#retrieval","text":"[source]","title":"Retrieval"},{"location":"generated/model/#get_model","text":"ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry.","title":"get_model"},{"location":"generated/model/#properties","text":"[source]","title":"Properties"},{"location":"generated/model/#created","text":"Creation date of the model. [source]","title":"created"},{"location":"generated/model/#description","text":"Description of the model. [source]","title":"description"},{"location":"generated/model/#environment","text":"Input example of the model. [source]","title":"environment"},{"location":"generated/model/#experiment_id","text":"Experiment Id of the model. [source]","title":"experiment_id"},{"location":"generated/model/#experiment_project_name","text":"experiment_project_name of the model. [source]","title":"experiment_project_name"},{"location":"generated/model/#framework","text":"framework of the model. [source]","title":"framework"},{"location":"generated/model/#id","text":"Id of the model. [source]","title":"id"},{"location":"generated/model/#input_example","text":"input_example of the model. [source]","title":"input_example"},{"location":"generated/model/#model_path","text":"path of the model with version folder omitted. Resolves to /Projects/{project_name}/Models/{name} [source]","title":"model_path"},{"location":"generated/model/#model_registry_id","text":"model_registry_id of the model. [source]","title":"model_registry_id"},{"location":"generated/model/#model_schema","text":"model schema of the model. [source]","title":"model_schema"},{"location":"generated/model/#name","text":"Name of the model. [source]","title":"name"},{"location":"generated/model/#program","text":"Executable used to export the model. [source]","title":"program"},{"location":"generated/model/#project_name","text":"project_name of the model. [source]","title":"project_name"},{"location":"generated/model/#shared_registry_project_name","text":"shared_registry_project_name of the model. [source]","title":"shared_registry_project_name"},{"location":"generated/model/#training_dataset","text":"training_dataset of the model. [source]","title":"training_dataset"},{"location":"generated/model/#training_metrics","text":"Training metrics of the model. [source]","title":"training_metrics"},{"location":"generated/model/#user","text":"user of the model. [source]","title":"user"},{"location":"generated/model/#version","text":"Version of the model. [source]","title":"version"},{"location":"generated/model/#version_path","text":"path of the model including version folder. Resolves to /Projects/{project_name}/Models/{name}/{version}","title":"version_path"},{"location":"generated/model/#methods","text":"[source]","title":"Methods"},{"location":"generated/model/#delete","text":"Model . delete () Delete the model Potentially dangerous operation This operation drops all metadata associated with this version of the model and deletes the model files. Raises RestAPIError . [source]","title":"delete"},{"location":"generated/model/#delete_tag","text":"Model . delete_tag ( name ) Delete a tag attached to a model. Arguments name str : Name of the tag to be removed. Raises RestAPIError in case the backend fails to delete the tag. [source]","title":"delete_tag"},{"location":"generated/model/#deploy","text":"Model . deploy ( name = None , artifact_version = \"CREATE\" , predictor_config = None , transformer_config = None ) Deploy the model [source]","title":"deploy"},{"location":"generated/model/#download","text":"Model . download () Download the model files to a local folder. [source]","title":"download"},{"location":"generated/model/#get_tag","text":"Model . get_tag ( name ) Get the tags of a model. Arguments name str : Name of the tag to get. Returns tag value Raises RestAPIError in case the backend fails to retrieve the tag. [source]","title":"get_tag"},{"location":"generated/model/#get_tags","text":"Model . get_tags () Retrieves all tags attached to a model. Returns Dict[str, obj] of tags. Raises RestAPIError in case the backend fails to retrieve the tags. [source]","title":"get_tags"},{"location":"generated/model/#save","text":"Model . save ( model_path , await_registration = 480 ) Persist this model including model files and metadata to the model registry. [source]","title":"save"},{"location":"generated/model/#set_tag","text":"Model . set_tag ( name , value ) Attach a tag to a model. A tag consists of a pair. Tag names are unique identifiers across the whole cluster. The value of a tag can be any valid json - primitives, arrays or json objects. Arguments name str : Name of the tag to be added. value Union[str, dict] : Value of the tag to be added. Raises RestAPIError in case the backend fails to add the tag.","title":"set_tag"},{"location":"generated/model_registry/","text":"Model Registry # Retrieval # [source] get_model_registry # Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. Properties # [source] model_registry_id # Id of the model registry. [source] project_id # Id of the project the registry is connected to. [source] project_name # Name of the project the registry is connected to. [source] python # Module for exporting a generic Python model. [source] shared_registry_project_name # Name of the project the shared model registry originates from. [source] sklearn # Module for exporting a sklearn model. [source] tensorflow # Module for exporting a TensorFlow model. [source] torch # Module for exporting a torch model. Methods # [source] get_best_model # ModelRegistry . get_best_model ( name , metric , direction ) Get the best performing model entity from the model registry. Getting the best performing model from the Model Registry means specifying in addition to the name, also a metric name corresponding to one of the keys in the training_metrics dict of the model and a direction. For example to get the model version with the highest accuracy, specify metric='accuracy' and direction='max'. Arguments name str : Name of the model to get. metric str : Name of the key in the training metrics field to compare. direction str : 'max' to get the model entity with the highest value of the set metric, or 'min' for the lowest. Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source] get_model # ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source] get_models # ModelRegistry . get_models ( name ) Get all model entities from the model registry for a specified name. Getting all models from the Model Registry for a given name returns a list of model entities, one for each version registered under the specified model name. Arguments name str : Name of the model to get. Returns List[Model] : A list of model metadata objects. Raises RestAPIError : If unable to retrieve model versions from the model registry.","title":"Model Registry"},{"location":"generated/model_registry/#model-registry","text":"","title":"Model Registry"},{"location":"generated/model_registry/#retrieval","text":"[source]","title":"Retrieval"},{"location":"generated/model_registry/#get_model_registry","text":"Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on.","title":"get_model_registry"},{"location":"generated/model_registry/#properties","text":"[source]","title":"Properties"},{"location":"generated/model_registry/#model_registry_id","text":"Id of the model registry. [source]","title":"model_registry_id"},{"location":"generated/model_registry/#project_id","text":"Id of the project the registry is connected to. [source]","title":"project_id"},{"location":"generated/model_registry/#project_name","text":"Name of the project the registry is connected to. [source]","title":"project_name"},{"location":"generated/model_registry/#python","text":"Module for exporting a generic Python model. [source]","title":"python"},{"location":"generated/model_registry/#shared_registry_project_name","text":"Name of the project the shared model registry originates from. [source]","title":"shared_registry_project_name"},{"location":"generated/model_registry/#sklearn","text":"Module for exporting a sklearn model. [source]","title":"sklearn"},{"location":"generated/model_registry/#tensorflow","text":"Module for exporting a TensorFlow model. [source]","title":"tensorflow"},{"location":"generated/model_registry/#torch","text":"Module for exporting a torch model.","title":"torch"},{"location":"generated/model_registry/#methods","text":"[source]","title":"Methods"},{"location":"generated/model_registry/#get_best_model","text":"ModelRegistry . get_best_model ( name , metric , direction ) Get the best performing model entity from the model registry. Getting the best performing model from the Model Registry means specifying in addition to the name, also a metric name corresponding to one of the keys in the training_metrics dict of the model and a direction. For example to get the model version with the highest accuracy, specify metric='accuracy' and direction='max'. Arguments name str : Name of the model to get. metric str : Name of the key in the training metrics field to compare. direction str : 'max' to get the model entity with the highest value of the set metric, or 'min' for the lowest. Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source]","title":"get_best_model"},{"location":"generated/model_registry/#get_model","text":"ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source]","title":"get_model"},{"location":"generated/model_registry/#get_models","text":"ModelRegistry . get_models ( name ) Get all model entities from the model registry for a specified name. Getting all models from the Model Registry for a given name returns a list of model entities, one for each version registered under the specified model name. Arguments name str : Name of the model to get. Returns List[Model] : A list of model metadata objects. Raises RestAPIError : If unable to retrieve model versions from the model registry.","title":"get_models"},{"location":"generated/model_schema/","text":"Model schema # A Model schema describes the input and outputs for a model. It provides a functional description of the model which makes it simpler to get started working with it. For example if the model inputs a tensor, the model schema can define the shape and data type of the tensor. A Model schema is composed of two Schema objects, one to describe the inputs and one to describe the outputs. It is not mandatory to define both the input and output schema when creating the Model schema. There are two different types of schemas, a column-based or tensor-based schema. Columnar schema # A column-based schema is composed of one or more columns, each column having a name if defined, and a data type. This maps directly to the schema you may find on for example a Spark or Pandas DataFrame. Build a schema # A column-based schema can be constructed manually by creating a list of dicts containing the mandatory type key which defines the data type. The optional keys name defines the column name, and description describe the field. In the following example, the model schema for a model trained on the Iris dataset is defined. # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs for iris dataset inputs = [{ 'name' : 'sepal_length' , 'type' : 'float' , 'description' : 'length of sepal leaves (cm)' }, { 'name' : 'sepal_width' , 'type' : 'float' , 'description' : 'width of sepal leaves (cm)' }, { 'name' : 'petal_length' , 'type' : 'float' , 'description' : 'length of petal leaves (cm)' }, { 'name' : 'petal_width' , 'type' : 'float' , 'description' : 'length of petal leaves (cm)' }] # Build the input schema input_schema = Schema ( inputs ) # Create ModelSchema object model_schema = ModelSchema ( input_schema = input_schema ) The created model schema can then be attached as metadata during creation of the Models object. import hsml conn = hsml . connection () mr = conn . get_model_registry () mnist_model = mr . python . create_model ( \"iris\" , model_schema = model_schema ) Infer a schema # A schema can also be inferred given a data object, such as for example a Pandas or Spark DataFrame. For a list of supported objects consult this . import pandas # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs defined in Pandas DataFrame data = [[ 5.1 , 3.5 , 1.4 , 0.2 ], [ 4.9 , 3.0 , 1.4 , 0.2 ]] pandas_df = pandas . DataFrame ( data , columns = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' ]) # Infer the inputs schema input_schema = Schema ( pandas_df ) # Create ModelSchema object ModelSchema ( input_schema = input_schema ) Tensor schema # A tensor-based schema consists of one or more tensors, each tensor having a data type and a shape. This maps directly to the schema you may find on a numpy.ndarray . Build a schema # An inputs or outputs schema can be constructed manually by creating a list of dicts containing the mandatory key type defining the data type and shape defining the shape of the tensor. The optional key name defines the tensor name and description describe the field. In the following example, the model schema for a model trained on the MNIST dataset is defined. # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs for MNIST dataset inputs = [{ 'type' : 'uint8' , 'shape' : [ 28 , 28 , 1 ], 'description' : 'grayscale representation of 28x28 MNIST images' }] # Build the input schema input_schema = Schema ( inputs ) # Model outputs outputs = [{ 'type' : 'float32' , 'shape' : [ 10 ]}] # Build the output schema output_schema = Schema ( outputs ) # Create ModelSchema object model_schema = ModelSchema ( input_schema = input_schema , output_schema = output_schema ) The created model schema can then be attached as metadata during creation of the Models object. import hsml conn = hsml . connection () mr = conn . get_model_registry () mnist_model = mr . tensorflow . create_model ( \"mnist\" , model_schema = model_schema ) Infer a schema # A Tensor schema can also be inferred given a data object, currently we support numpy.ndarray . For a list of supported objects consult this . import numpy # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs defined in numpy.ndarray ndarr = numpy . random . rand ( 28 , 28 , 1 ) . astype ( \"uint8\" ) # Infer the inputs schema input_schema = Schema ( ndarr ) # Create ModelSchema object ModelSchema ( input_schema = input_schema )","title":"Model Schema"},{"location":"generated/model_schema/#model-schema","text":"A Model schema describes the input and outputs for a model. It provides a functional description of the model which makes it simpler to get started working with it. For example if the model inputs a tensor, the model schema can define the shape and data type of the tensor. A Model schema is composed of two Schema objects, one to describe the inputs and one to describe the outputs. It is not mandatory to define both the input and output schema when creating the Model schema. There are two different types of schemas, a column-based or tensor-based schema.","title":"Model schema"},{"location":"generated/model_schema/#columnar-schema","text":"A column-based schema is composed of one or more columns, each column having a name if defined, and a data type. This maps directly to the schema you may find on for example a Spark or Pandas DataFrame.","title":"Columnar schema"},{"location":"generated/model_schema/#build-a-schema","text":"A column-based schema can be constructed manually by creating a list of dicts containing the mandatory type key which defines the data type. The optional keys name defines the column name, and description describe the field. In the following example, the model schema for a model trained on the Iris dataset is defined. # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs for iris dataset inputs = [{ 'name' : 'sepal_length' , 'type' : 'float' , 'description' : 'length of sepal leaves (cm)' }, { 'name' : 'sepal_width' , 'type' : 'float' , 'description' : 'width of sepal leaves (cm)' }, { 'name' : 'petal_length' , 'type' : 'float' , 'description' : 'length of petal leaves (cm)' }, { 'name' : 'petal_width' , 'type' : 'float' , 'description' : 'length of petal leaves (cm)' }] # Build the input schema input_schema = Schema ( inputs ) # Create ModelSchema object model_schema = ModelSchema ( input_schema = input_schema ) The created model schema can then be attached as metadata during creation of the Models object. import hsml conn = hsml . connection () mr = conn . get_model_registry () mnist_model = mr . python . create_model ( \"iris\" , model_schema = model_schema )","title":"Build a schema"},{"location":"generated/model_schema/#infer-a-schema","text":"A schema can also be inferred given a data object, such as for example a Pandas or Spark DataFrame. For a list of supported objects consult this . import pandas # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs defined in Pandas DataFrame data = [[ 5.1 , 3.5 , 1.4 , 0.2 ], [ 4.9 , 3.0 , 1.4 , 0.2 ]] pandas_df = pandas . DataFrame ( data , columns = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' ]) # Infer the inputs schema input_schema = Schema ( pandas_df ) # Create ModelSchema object ModelSchema ( input_schema = input_schema )","title":"Infer a schema"},{"location":"generated/model_schema/#tensor-schema","text":"A tensor-based schema consists of one or more tensors, each tensor having a data type and a shape. This maps directly to the schema you may find on a numpy.ndarray .","title":"Tensor schema"},{"location":"generated/model_schema/#build-a-schema_1","text":"An inputs or outputs schema can be constructed manually by creating a list of dicts containing the mandatory key type defining the data type and shape defining the shape of the tensor. The optional key name defines the tensor name and description describe the field. In the following example, the model schema for a model trained on the MNIST dataset is defined. # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs for MNIST dataset inputs = [{ 'type' : 'uint8' , 'shape' : [ 28 , 28 , 1 ], 'description' : 'grayscale representation of 28x28 MNIST images' }] # Build the input schema input_schema = Schema ( inputs ) # Model outputs outputs = [{ 'type' : 'float32' , 'shape' : [ 10 ]}] # Build the output schema output_schema = Schema ( outputs ) # Create ModelSchema object model_schema = ModelSchema ( input_schema = input_schema , output_schema = output_schema ) The created model schema can then be attached as metadata during creation of the Models object. import hsml conn = hsml . connection () mr = conn . get_model_registry () mnist_model = mr . tensorflow . create_model ( \"mnist\" , model_schema = model_schema )","title":"Build a schema"},{"location":"generated/model_schema/#infer-a-schema_1","text":"A Tensor schema can also be inferred given a data object, currently we support numpy.ndarray . For a list of supported objects consult this . import numpy # Import a Schema and ModelSchema definition from hsml.utils.model_schema import ModelSchema from hsml.utils.schema import Schema # Model inputs defined in numpy.ndarray ndarr = numpy . random . rand ( 28 , 28 , 1 ) . astype ( \"uint8\" ) # Infer the inputs schema input_schema = Schema ( ndarr ) # Create ModelSchema object ModelSchema ( input_schema = input_schema )","title":"Infer a schema"},{"location":"generated/project/","text":"Project/Connection # In Hopsworks a Project is a sandboxed set of users, data, and programs (where data can be shared in a controlled manner between projects). Each Project can have its own Model Registry. However, it is possible to share Model Registry among projects. When working with the Model Registry from a programming environment you can connect to a single Hopsworks instance at a time, but it is possible to access multiple Model Registries simultaneously. A connection to a Hopsworks instance is represented by a Connection object . Its main purpose is to retrieve the API Key if you are connecting from an external environment. The handle can then be used to retrieve a reference to the Model Registry you want to operate on. Examples # Python Connecting from Hopsworks import hsml conn = hsml . connection () mr = conn . get_model_registry () Connecting from Python environment To connect from an external Python environment you can provide the api_key_value directly: import hsml conn = hsml . connection ( host = \"ec2-13-53-124-128.eu-north-1.compute.amazonaws.com\" , project = \"demo_ml_admin000\" , hostname_verification = False , api_key_value = \"PFcy3dZ6wLXYglRd.ydcdq5jH878IdG7xlL9lHVqrS8v3sBUqQgyR4xbpUgDnB5ZpYro6O\" ) mr = conn . get_model_registry () Alternatively you can pass the API Key as a file or directly: import hsml conn = hsml . connection ( host = \"ec2-13-53-124-128.eu-north-1.compute.amazonaws.com\" , project = \"demo_ml_admin000\" , hostname_verification = False , api_key_file = \"modelregistry.key\" ) mr = conn . get_model_registry () Sharing a Model Registry # Connections are on a project-level, however, it is possible to share model registries among projects, so even if you have a connection to one project, you can retrieve a handle to any model registry shared with that project. To share a model registry, you can follow these steps: Sharing a Model Registry Open the project of the model registry that you would like to share on Hopsworks. Go to the Data Set browser and right click the Models entry. Click Share with , then select Project and choose the project you wish to share the model registry with. Select the permissions level that the project user members should have on the model registry and click Share . Open the project you just shared the model registry with. Go to the Data Sets browser and there you should see the shared model registry as [project_name_of_shared_model_registry]::Models . Click this entry, you will be asked to accept this shared Dataset, click Accept . You should now have access to this model registry from the other project. Sharing a model registry between projects Accepting a shared model registry from a project Connection Handle # [source] Connection # hsml . connection . Connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) A Model registry connection object. The connection is project specific, so you can access the project's own model registry. This class provides convenience classmethods accessible from the hsml -module: Connection factory For convenience, hsml provides a factory method, accessible from the top level module, so you don't have to import the Connection class manually: import hsml conn = hsml . connection () Save API Key as File To get started quickly, without saving the Hopsworks API in a secret storage, you can simply create a file with the previously created Hopsworks API Key and place it on the environment from which you wish to connect to the Hopsworks Model Registry. You can then connect by simply passing the path to the key file when instantiating a connection: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project api_key_file = 'modelregistry.key' , # The file containing the API key generated above hostname_verification = True ) # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry ms = conn . get_model_serving () # Get the project's default model serving Clients in external clusters need to connect to the Hopsworks Model Registry using an API key. The API key is generated inside the Hopsworks platform, and requires at least the \"project\", \"modelregistry\", \"dataset.create\", \"dataset.view\", \"dataset.delete\", \"serving\" scopes to be able to access a model registry and its model serving. For more information, see the integration guides . Arguments host Optional[str] : The hostname of the Hopsworks instance, defaults to None . port int : The port on which the Hopsworks instance can be reached, defaults to 443 . project Optional[str] : The name of the project to connect to. When running on Hopsworks, this defaults to the project from where the client is run from. Defaults to None . region_name str : The name of the AWS region in which the required secrets are stored, defaults to \"default\" . secrets_store str : The secrets storage to be used, either \"secretsmanager\" , \"parameterstore\" or \"local\" , defaults to \"parameterstore\" . hostname_verification bool : Whether or not to verify Hopsworks certificate, defaults to True . trust_store_path Optional[str] : Path on the file system containing the Hopsworks certificates, defaults to None . api_key_file Optional[str] : Path to a file containing the API Key, if provided, secrets_store will be ignored, defaults to None . api_key_value Optional[str] : API Key as string, if provided, secrets_store will be ignored , however, this should be used with care, especially if the used notebook or job script is accessible by multiple parties. Defaults to None`. Returns Connection . Connection handle to perform operations on a Hopsworks project. Methods # [source] close # Connection . close () Close a connection gracefully. This will clean up any materialized certificates on the local file system of external environments such as AWS SageMaker. Usage is recommended but optional. [source] connect # Connection . connect () Instantiate the connection. Creating a Connection object implicitly calls this method for you to instantiate the connection. However, it is possible to close the connection gracefully with the close() method, in order to clean up materialized certificates. This might be desired when working on external environments such as AWS SageMaker. Subsequently you can call connect() again to reopen the connection. Example import hsml conn = hsml . connection () conn . close () conn . connect () [source] get_model_registry # Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. [source] get_model_serving # Connection . get_model_serving () Get a reference to model serving to perform operations on. Model serving operates on top of a model registry. Connecting to the project's default model registry. Returns ModelServing . A model serving handle object to perform operations on.","title":"Project/Connection"},{"location":"generated/project/#projectconnection","text":"In Hopsworks a Project is a sandboxed set of users, data, and programs (where data can be shared in a controlled manner between projects). Each Project can have its own Model Registry. However, it is possible to share Model Registry among projects. When working with the Model Registry from a programming environment you can connect to a single Hopsworks instance at a time, but it is possible to access multiple Model Registries simultaneously. A connection to a Hopsworks instance is represented by a Connection object . Its main purpose is to retrieve the API Key if you are connecting from an external environment. The handle can then be used to retrieve a reference to the Model Registry you want to operate on.","title":"Project/Connection"},{"location":"generated/project/#examples","text":"Python Connecting from Hopsworks import hsml conn = hsml . connection () mr = conn . get_model_registry () Connecting from Python environment To connect from an external Python environment you can provide the api_key_value directly: import hsml conn = hsml . connection ( host = \"ec2-13-53-124-128.eu-north-1.compute.amazonaws.com\" , project = \"demo_ml_admin000\" , hostname_verification = False , api_key_value = \"PFcy3dZ6wLXYglRd.ydcdq5jH878IdG7xlL9lHVqrS8v3sBUqQgyR4xbpUgDnB5ZpYro6O\" ) mr = conn . get_model_registry () Alternatively you can pass the API Key as a file or directly: import hsml conn = hsml . connection ( host = \"ec2-13-53-124-128.eu-north-1.compute.amazonaws.com\" , project = \"demo_ml_admin000\" , hostname_verification = False , api_key_file = \"modelregistry.key\" ) mr = conn . get_model_registry ()","title":"Examples"},{"location":"generated/project/#sharing-a-model-registry","text":"Connections are on a project-level, however, it is possible to share model registries among projects, so even if you have a connection to one project, you can retrieve a handle to any model registry shared with that project. To share a model registry, you can follow these steps: Sharing a Model Registry Open the project of the model registry that you would like to share on Hopsworks. Go to the Data Set browser and right click the Models entry. Click Share with , then select Project and choose the project you wish to share the model registry with. Select the permissions level that the project user members should have on the model registry and click Share . Open the project you just shared the model registry with. Go to the Data Sets browser and there you should see the shared model registry as [project_name_of_shared_model_registry]::Models . Click this entry, you will be asked to accept this shared Dataset, click Accept . You should now have access to this model registry from the other project. Sharing a model registry between projects Accepting a shared model registry from a project","title":"Sharing a Model Registry"},{"location":"generated/project/#connection-handle","text":"[source]","title":"Connection Handle"},{"location":"generated/project/#connection","text":"hsml . connection . Connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) A Model registry connection object. The connection is project specific, so you can access the project's own model registry. This class provides convenience classmethods accessible from the hsml -module: Connection factory For convenience, hsml provides a factory method, accessible from the top level module, so you don't have to import the Connection class manually: import hsml conn = hsml . connection () Save API Key as File To get started quickly, without saving the Hopsworks API in a secret storage, you can simply create a file with the previously created Hopsworks API Key and place it on the environment from which you wish to connect to the Hopsworks Model Registry. You can then connect by simply passing the path to the key file when instantiating a connection: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project api_key_file = 'modelregistry.key' , # The file containing the API key generated above hostname_verification = True ) # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry ms = conn . get_model_serving () # Get the project's default model serving Clients in external clusters need to connect to the Hopsworks Model Registry using an API key. The API key is generated inside the Hopsworks platform, and requires at least the \"project\", \"modelregistry\", \"dataset.create\", \"dataset.view\", \"dataset.delete\", \"serving\" scopes to be able to access a model registry and its model serving. For more information, see the integration guides . Arguments host Optional[str] : The hostname of the Hopsworks instance, defaults to None . port int : The port on which the Hopsworks instance can be reached, defaults to 443 . project Optional[str] : The name of the project to connect to. When running on Hopsworks, this defaults to the project from where the client is run from. Defaults to None . region_name str : The name of the AWS region in which the required secrets are stored, defaults to \"default\" . secrets_store str : The secrets storage to be used, either \"secretsmanager\" , \"parameterstore\" or \"local\" , defaults to \"parameterstore\" . hostname_verification bool : Whether or not to verify Hopsworks certificate, defaults to True . trust_store_path Optional[str] : Path on the file system containing the Hopsworks certificates, defaults to None . api_key_file Optional[str] : Path to a file containing the API Key, if provided, secrets_store will be ignored, defaults to None . api_key_value Optional[str] : API Key as string, if provided, secrets_store will be ignored , however, this should be used with care, especially if the used notebook or job script is accessible by multiple parties. Defaults to None`. Returns Connection . Connection handle to perform operations on a Hopsworks project.","title":"Connection"},{"location":"generated/project/#methods","text":"[source]","title":"Methods"},{"location":"generated/project/#close","text":"Connection . close () Close a connection gracefully. This will clean up any materialized certificates on the local file system of external environments such as AWS SageMaker. Usage is recommended but optional. [source]","title":"close"},{"location":"generated/project/#connect","text":"Connection . connect () Instantiate the connection. Creating a Connection object implicitly calls this method for you to instantiate the connection. However, it is possible to close the connection gracefully with the close() method, in order to clean up materialized certificates. This might be desired when working on external environments such as AWS SageMaker. Subsequently you can call connect() again to reopen the connection. Example import hsml conn = hsml . connection () conn . close () conn . connect () [source]","title":"connect"},{"location":"generated/project/#get_model_registry","text":"Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. [source]","title":"get_model_registry"},{"location":"generated/project/#get_model_serving","text":"Connection . get_model_serving () Get a reference to model serving to perform operations on. Model serving operates on top of a model registry. Connecting to the project's default model registry. Returns ModelServing . A model serving handle object to perform operations on.","title":"get_model_serving"},{"location":"generated/api/connection_api/","text":"Connection # [source] Connection # hsml . connection . Connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) A Model registry connection object. The connection is project specific, so you can access the project's own model registry. This class provides convenience classmethods accessible from the hsml -module: Connection factory For convenience, hsml provides a factory method, accessible from the top level module, so you don't have to import the Connection class manually: import hsml conn = hsml . connection () Save API Key as File To get started quickly, without saving the Hopsworks API in a secret storage, you can simply create a file with the previously created Hopsworks API Key and place it on the environment from which you wish to connect to the Hopsworks Model Registry. You can then connect by simply passing the path to the key file when instantiating a connection: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project api_key_file = 'modelregistry.key' , # The file containing the API key generated above hostname_verification = True ) # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry ms = conn . get_model_serving () # Get the project's default model serving Clients in external clusters need to connect to the Hopsworks Model Registry using an API key. The API key is generated inside the Hopsworks platform, and requires at least the \"project\", \"modelregistry\", \"dataset.create\", \"dataset.view\", \"dataset.delete\", \"serving\" scopes to be able to access a model registry and its model serving. For more information, see the integration guides . Arguments host Optional[str] : The hostname of the Hopsworks instance, defaults to None . port int : The port on which the Hopsworks instance can be reached, defaults to 443 . project Optional[str] : The name of the project to connect to. When running on Hopsworks, this defaults to the project from where the client is run from. Defaults to None . region_name str : The name of the AWS region in which the required secrets are stored, defaults to \"default\" . secrets_store str : The secrets storage to be used, either \"secretsmanager\" , \"parameterstore\" or \"local\" , defaults to \"parameterstore\" . hostname_verification bool : Whether or not to verify Hopsworks certificate, defaults to True . trust_store_path Optional[str] : Path on the file system containing the Hopsworks certificates, defaults to None . api_key_file Optional[str] : Path to a file containing the API Key, if provided, secrets_store will be ignored, defaults to None . api_key_value Optional[str] : API Key as string, if provided, secrets_store will be ignored , however, this should be used with care, especially if the used notebook or job script is accessible by multiple parties. Defaults to None`. Returns Connection . Connection handle to perform operations on a Hopsworks project. Properties # [source] api_key_file # [source] api_key_value # [source] host # [source] hostname_verification # [source] port # [source] project # [source] region_name # [source] secrets_store # [source] trust_store_path # Methods # [source] close # Connection . close () Close a connection gracefully. This will clean up any materialized certificates on the local file system of external environments such as AWS SageMaker. Usage is recommended but optional. [source] connect # Connection . connect () Instantiate the connection. Creating a Connection object implicitly calls this method for you to instantiate the connection. However, it is possible to close the connection gracefully with the close() method, in order to clean up materialized certificates. This might be desired when working on external environments such as AWS SageMaker. Subsequently you can call connect() again to reopen the connection. Example import hsml conn = hsml . connection () conn . close () conn . connect () [source] connection # Connection . connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) Connection factory method, accessible through hsml.connection() . [source] get_model_registry # Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. [source] get_model_serving # Connection . get_model_serving () Get a reference to model serving to perform operations on. Model serving operates on top of a model registry. Connecting to the project's default model registry. Returns ModelServing . A model serving handle object to perform operations on.","title":"Connection"},{"location":"generated/api/connection_api/#connection","text":"[source]","title":"Connection"},{"location":"generated/api/connection_api/#connection_1","text":"hsml . connection . Connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) A Model registry connection object. The connection is project specific, so you can access the project's own model registry. This class provides convenience classmethods accessible from the hsml -module: Connection factory For convenience, hsml provides a factory method, accessible from the top level module, so you don't have to import the Connection class manually: import hsml conn = hsml . connection () Save API Key as File To get started quickly, without saving the Hopsworks API in a secret storage, you can simply create a file with the previously created Hopsworks API Key and place it on the environment from which you wish to connect to the Hopsworks Model Registry. You can then connect by simply passing the path to the key file when instantiating a connection: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project api_key_file = 'modelregistry.key' , # The file containing the API key generated above hostname_verification = True ) # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry ms = conn . get_model_serving () # Get the project's default model serving Clients in external clusters need to connect to the Hopsworks Model Registry using an API key. The API key is generated inside the Hopsworks platform, and requires at least the \"project\", \"modelregistry\", \"dataset.create\", \"dataset.view\", \"dataset.delete\", \"serving\" scopes to be able to access a model registry and its model serving. For more information, see the integration guides . Arguments host Optional[str] : The hostname of the Hopsworks instance, defaults to None . port int : The port on which the Hopsworks instance can be reached, defaults to 443 . project Optional[str] : The name of the project to connect to. When running on Hopsworks, this defaults to the project from where the client is run from. Defaults to None . region_name str : The name of the AWS region in which the required secrets are stored, defaults to \"default\" . secrets_store str : The secrets storage to be used, either \"secretsmanager\" , \"parameterstore\" or \"local\" , defaults to \"parameterstore\" . hostname_verification bool : Whether or not to verify Hopsworks certificate, defaults to True . trust_store_path Optional[str] : Path on the file system containing the Hopsworks certificates, defaults to None . api_key_file Optional[str] : Path to a file containing the API Key, if provided, secrets_store will be ignored, defaults to None . api_key_value Optional[str] : API Key as string, if provided, secrets_store will be ignored , however, this should be used with care, especially if the used notebook or job script is accessible by multiple parties. Defaults to None`. Returns Connection . Connection handle to perform operations on a Hopsworks project.","title":"Connection"},{"location":"generated/api/connection_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/connection_api/#api_key_file","text":"[source]","title":"api_key_file"},{"location":"generated/api/connection_api/#api_key_value","text":"[source]","title":"api_key_value"},{"location":"generated/api/connection_api/#host","text":"[source]","title":"host"},{"location":"generated/api/connection_api/#hostname_verification","text":"[source]","title":"hostname_verification"},{"location":"generated/api/connection_api/#port","text":"[source]","title":"port"},{"location":"generated/api/connection_api/#project","text":"[source]","title":"project"},{"location":"generated/api/connection_api/#region_name","text":"[source]","title":"region_name"},{"location":"generated/api/connection_api/#secrets_store","text":"[source]","title":"secrets_store"},{"location":"generated/api/connection_api/#trust_store_path","text":"","title":"trust_store_path"},{"location":"generated/api/connection_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/connection_api/#close","text":"Connection . close () Close a connection gracefully. This will clean up any materialized certificates on the local file system of external environments such as AWS SageMaker. Usage is recommended but optional. [source]","title":"close"},{"location":"generated/api/connection_api/#connect","text":"Connection . connect () Instantiate the connection. Creating a Connection object implicitly calls this method for you to instantiate the connection. However, it is possible to close the connection gracefully with the close() method, in order to clean up materialized certificates. This might be desired when working on external environments such as AWS SageMaker. Subsequently you can call connect() again to reopen the connection. Example import hsml conn = hsml . connection () conn . close () conn . connect () [source]","title":"connect"},{"location":"generated/api/connection_api/#connection_2","text":"Connection . connection ( host = None , port = 443 , project = None , region_name = \"default\" , secrets_store = \"parameterstore\" , hostname_verification = True , trust_store_path = None , api_key_file = None , api_key_value = None , ) Connection factory method, accessible through hsml.connection() . [source]","title":"connection"},{"location":"generated/api/connection_api/#get_model_registry","text":"Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. [source]","title":"get_model_registry"},{"location":"generated/api/connection_api/#get_model_serving","text":"Connection . get_model_serving () Get a reference to model serving to perform operations on. Model serving operates on top of a model registry. Connecting to the project's default model registry. Returns ModelServing . A model serving handle object to perform operations on.","title":"get_model_serving"},{"location":"generated/api/model_api/","text":"TensorFlow model creation # [source] create_model # hsml . model_registry . ModelRegistry . tensorflow . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a TensorFlow model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. Torch model creation # [source] create_model # hsml . model_registry . ModelRegistry . torch . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a Torch model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. Sklearn model creation # [source] create_model # hsml . model_registry . ModelRegistry . sklearn . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create an SkLearn model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. Generic model creation # [source] create_model # hsml . model_registry . ModelRegistry . python . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a generic Python model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object. Retrieval # [source] get_model # ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. Properties # [source] created # Creation date of the model. [source] description # Description of the model. [source] environment # Input example of the model. [source] experiment_id # Experiment Id of the model. [source] experiment_project_name # experiment_project_name of the model. [source] framework # framework of the model. [source] id # Id of the model. [source] input_example # input_example of the model. [source] model_path # path of the model with version folder omitted. Resolves to /Projects/{project_name}/Models/{name} [source] model_registry_id # model_registry_id of the model. [source] model_schema # model schema of the model. [source] name # Name of the model. [source] program # Executable used to export the model. [source] project_name # project_name of the model. [source] shared_registry_project_name # shared_registry_project_name of the model. [source] training_dataset # training_dataset of the model. [source] training_metrics # Training metrics of the model. [source] user # user of the model. [source] version # Version of the model. [source] version_path # path of the model including version folder. Resolves to /Projects/{project_name}/Models/{name}/{version} Methods # [source] delete # Model . delete () Delete the model Potentially dangerous operation This operation drops all metadata associated with this version of the model and deletes the model files. Raises RestAPIError . [source] delete_tag # Model . delete_tag ( name ) Delete a tag attached to a model. Arguments name str : Name of the tag to be removed. Raises RestAPIError in case the backend fails to delete the tag. [source] deploy # Model . deploy ( name = None , artifact_version = \"CREATE\" , predictor_config = None , transformer_config = None ) Deploy the model [source] download # Model . download () Download the model files to a local folder. [source] get_tag # Model . get_tag ( name ) Get the tags of a model. Arguments name str : Name of the tag to get. Returns tag value Raises RestAPIError in case the backend fails to retrieve the tag. [source] get_tags # Model . get_tags () Retrieves all tags attached to a model. Returns Dict[str, obj] of tags. Raises RestAPIError in case the backend fails to retrieve the tags. [source] save # Model . save ( model_path , await_registration = 480 ) Persist this model including model files and metadata to the model registry. [source] set_tag # Model . set_tag ( name , value ) Attach a tag to a model. A tag consists of a pair. Tag names are unique identifiers across the whole cluster. The value of a tag can be any valid json - primitives, arrays or json objects. Arguments name str : Name of the tag to be added. value Union[str, dict] : Value of the tag to be added. Raises RestAPIError in case the backend fails to add the tag.","title":"Model"},{"location":"generated/api/model_api/#tensorflow-model-creation","text":"[source]","title":"TensorFlow model creation"},{"location":"generated/api/model_api/#create_model","text":"hsml . model_registry . ModelRegistry . tensorflow . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a TensorFlow model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object.","title":"create_model"},{"location":"generated/api/model_api/#torch-model-creation","text":"[source]","title":"Torch model creation"},{"location":"generated/api/model_api/#create_model_1","text":"hsml . model_registry . ModelRegistry . torch . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a Torch model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object.","title":"create_model"},{"location":"generated/api/model_api/#sklearn-model-creation","text":"[source]","title":"Sklearn model creation"},{"location":"generated/api/model_api/#create_model_2","text":"hsml . model_registry . ModelRegistry . sklearn . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create an SkLearn model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object.","title":"create_model"},{"location":"generated/api/model_api/#generic-model-creation","text":"[source]","title":"Generic model creation"},{"location":"generated/api/model_api/#create_model_3","text":"hsml . model_registry . ModelRegistry . python . create_model ( name , version = None , metrics = None , description = None , input_example = None , model_schema = None ) Create a generic Python model metadata object. Lazy This method is lazy and does not persist any metadata or uploads model artifacts in the model registry on its own. To save the model object and the model artifacts, call the save() method with a local file path to the directory containing the model artifacts. Arguments name str : Name of the model to create. version Optional[int] : Optionally version of the model to create, defaults to None and will create the model with incremented version from the last version in the model registry. description Optional[str] : Optionally a string describing the model, defaults to empty string \"\" . input_example Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, numpy.ndarray, list]] : Optionally an input example that represents inputs for the model, defaults to None . model_schema Optional[hsml.model_schema.ModelSchema] : Optionally a model schema for the model inputs and/or outputs. Returns Model . The model metadata object.","title":"create_model"},{"location":"generated/api/model_api/#retrieval","text":"[source]","title":"Retrieval"},{"location":"generated/api/model_api/#get_model","text":"ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry.","title":"get_model"},{"location":"generated/api/model_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/model_api/#created","text":"Creation date of the model. [source]","title":"created"},{"location":"generated/api/model_api/#description","text":"Description of the model. [source]","title":"description"},{"location":"generated/api/model_api/#environment","text":"Input example of the model. [source]","title":"environment"},{"location":"generated/api/model_api/#experiment_id","text":"Experiment Id of the model. [source]","title":"experiment_id"},{"location":"generated/api/model_api/#experiment_project_name","text":"experiment_project_name of the model. [source]","title":"experiment_project_name"},{"location":"generated/api/model_api/#framework","text":"framework of the model. [source]","title":"framework"},{"location":"generated/api/model_api/#id","text":"Id of the model. [source]","title":"id"},{"location":"generated/api/model_api/#input_example","text":"input_example of the model. [source]","title":"input_example"},{"location":"generated/api/model_api/#model_path","text":"path of the model with version folder omitted. Resolves to /Projects/{project_name}/Models/{name} [source]","title":"model_path"},{"location":"generated/api/model_api/#model_registry_id","text":"model_registry_id of the model. [source]","title":"model_registry_id"},{"location":"generated/api/model_api/#model_schema","text":"model schema of the model. [source]","title":"model_schema"},{"location":"generated/api/model_api/#name","text":"Name of the model. [source]","title":"name"},{"location":"generated/api/model_api/#program","text":"Executable used to export the model. [source]","title":"program"},{"location":"generated/api/model_api/#project_name","text":"project_name of the model. [source]","title":"project_name"},{"location":"generated/api/model_api/#shared_registry_project_name","text":"shared_registry_project_name of the model. [source]","title":"shared_registry_project_name"},{"location":"generated/api/model_api/#training_dataset","text":"training_dataset of the model. [source]","title":"training_dataset"},{"location":"generated/api/model_api/#training_metrics","text":"Training metrics of the model. [source]","title":"training_metrics"},{"location":"generated/api/model_api/#user","text":"user of the model. [source]","title":"user"},{"location":"generated/api/model_api/#version","text":"Version of the model. [source]","title":"version"},{"location":"generated/api/model_api/#version_path","text":"path of the model including version folder. Resolves to /Projects/{project_name}/Models/{name}/{version}","title":"version_path"},{"location":"generated/api/model_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/model_api/#delete","text":"Model . delete () Delete the model Potentially dangerous operation This operation drops all metadata associated with this version of the model and deletes the model files. Raises RestAPIError . [source]","title":"delete"},{"location":"generated/api/model_api/#delete_tag","text":"Model . delete_tag ( name ) Delete a tag attached to a model. Arguments name str : Name of the tag to be removed. Raises RestAPIError in case the backend fails to delete the tag. [source]","title":"delete_tag"},{"location":"generated/api/model_api/#deploy","text":"Model . deploy ( name = None , artifact_version = \"CREATE\" , predictor_config = None , transformer_config = None ) Deploy the model [source]","title":"deploy"},{"location":"generated/api/model_api/#download","text":"Model . download () Download the model files to a local folder. [source]","title":"download"},{"location":"generated/api/model_api/#get_tag","text":"Model . get_tag ( name ) Get the tags of a model. Arguments name str : Name of the tag to get. Returns tag value Raises RestAPIError in case the backend fails to retrieve the tag. [source]","title":"get_tag"},{"location":"generated/api/model_api/#get_tags","text":"Model . get_tags () Retrieves all tags attached to a model. Returns Dict[str, obj] of tags. Raises RestAPIError in case the backend fails to retrieve the tags. [source]","title":"get_tags"},{"location":"generated/api/model_api/#save","text":"Model . save ( model_path , await_registration = 480 ) Persist this model including model files and metadata to the model registry. [source]","title":"save"},{"location":"generated/api/model_api/#set_tag","text":"Model . set_tag ( name , value ) Attach a tag to a model. A tag consists of a pair. Tag names are unique identifiers across the whole cluster. The value of a tag can be any valid json - primitives, arrays or json objects. Arguments name str : Name of the tag to be added. value Union[str, dict] : Value of the tag to be added. Raises RestAPIError in case the backend fails to add the tag.","title":"set_tag"},{"location":"generated/api/model_registry_api/","text":"Model Registry # [source] ModelRegistry # hsml . model_registry . ModelRegistry ( project_name , project_id , model_registry_id , shared_registry_project_name = None ) Retrieval # [source] get_model_registry # Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on. Properties # [source] model_registry_id # Id of the model registry. [source] project_id # Id of the project the registry is connected to. [source] project_name # Name of the project the registry is connected to. [source] python # Module for exporting a generic Python model. [source] shared_registry_project_name # Name of the project the shared model registry originates from. [source] sklearn # Module for exporting a sklearn model. [source] tensorflow # Module for exporting a TensorFlow model. [source] torch # Module for exporting a torch model. Methods # [source] get_best_model # ModelRegistry . get_best_model ( name , metric , direction ) Get the best performing model entity from the model registry. Getting the best performing model from the Model Registry means specifying in addition to the name, also a metric name corresponding to one of the keys in the training_metrics dict of the model and a direction. For example to get the model version with the highest accuracy, specify metric='accuracy' and direction='max'. Arguments name str : Name of the model to get. metric str : Name of the key in the training metrics field to compare. direction str : 'max' to get the model entity with the highest value of the set metric, or 'min' for the lowest. Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source] get_model # ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source] get_models # ModelRegistry . get_models ( name ) Get all model entities from the model registry for a specified name. Getting all models from the Model Registry for a given name returns a list of model entities, one for each version registered under the specified model name. Arguments name str : Name of the model to get. Returns List[Model] : A list of model metadata objects. Raises RestAPIError : If unable to retrieve model versions from the model registry.","title":"ModelRegistry"},{"location":"generated/api/model_registry_api/#model-registry","text":"[source]","title":"Model Registry"},{"location":"generated/api/model_registry_api/#modelregistry","text":"hsml . model_registry . ModelRegistry ( project_name , project_id , model_registry_id , shared_registry_project_name = None )","title":"ModelRegistry"},{"location":"generated/api/model_registry_api/#retrieval","text":"[source]","title":"Retrieval"},{"location":"generated/api/model_registry_api/#get_model_registry","text":"Connection . get_model_registry ( project = None ) Get a reference to a model registry to perform operations on. Defaulting to the project's default model registry. Shared model registries can be retrieved by passing the project argument. Arguments project str : The name of the project that owns the shared model registry, the model registry must be shared with the project the connection was established for, defaults to None . Returns ModelRegistry . A model registry handle object to perform operations on.","title":"get_model_registry"},{"location":"generated/api/model_registry_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/model_registry_api/#model_registry_id","text":"Id of the model registry. [source]","title":"model_registry_id"},{"location":"generated/api/model_registry_api/#project_id","text":"Id of the project the registry is connected to. [source]","title":"project_id"},{"location":"generated/api/model_registry_api/#project_name","text":"Name of the project the registry is connected to. [source]","title":"project_name"},{"location":"generated/api/model_registry_api/#python","text":"Module for exporting a generic Python model. [source]","title":"python"},{"location":"generated/api/model_registry_api/#shared_registry_project_name","text":"Name of the project the shared model registry originates from. [source]","title":"shared_registry_project_name"},{"location":"generated/api/model_registry_api/#sklearn","text":"Module for exporting a sklearn model. [source]","title":"sklearn"},{"location":"generated/api/model_registry_api/#tensorflow","text":"Module for exporting a TensorFlow model. [source]","title":"tensorflow"},{"location":"generated/api/model_registry_api/#torch","text":"Module for exporting a torch model.","title":"torch"},{"location":"generated/api/model_registry_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/model_registry_api/#get_best_model","text":"ModelRegistry . get_best_model ( name , metric , direction ) Get the best performing model entity from the model registry. Getting the best performing model from the Model Registry means specifying in addition to the name, also a metric name corresponding to one of the keys in the training_metrics dict of the model and a direction. For example to get the model version with the highest accuracy, specify metric='accuracy' and direction='max'. Arguments name str : Name of the model to get. metric str : Name of the key in the training metrics field to compare. direction str : 'max' to get the model entity with the highest value of the set metric, or 'min' for the lowest. Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source]","title":"get_best_model"},{"location":"generated/api/model_registry_api/#get_model","text":"ModelRegistry . get_model ( name , version = None ) Get a model entity from the model registry. Getting a model from the Model Registry means getting its metadata handle so you can subsequently download the model directory. Arguments name str : Name of the model to get. version Optional[int] : Version of the model to retrieve, defaults to None and will return the version=1 . Returns Model : The model metadata object. Raises RestAPIError : If unable to retrieve model from the model registry. [source]","title":"get_model"},{"location":"generated/api/model_registry_api/#get_models","text":"ModelRegistry . get_models ( name ) Get all model entities from the model registry for a specified name. Getting all models from the Model Registry for a given name returns a list of model entities, one for each version registered under the specified model name. Arguments name str : Name of the model to get. Returns List[Model] : A list of model metadata objects. Raises RestAPIError : If unable to retrieve model versions from the model registry.","title":"get_models"},{"location":"generated/api/model_schema_api/","text":"Schema # [source] Schema # hsml . schema . Schema ( object = None ) Create a schema for a model input or output. Arguments object Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, pyspark.sql.dataframe.DataFrame, hsfs.training_dataset.TrainingDataset, numpy.ndarray, list]] : The object to construct the schema from. Returns Schema . The schema object. [source] to_dict # Schema . to_dict () Get dict representation of the Schema. ModelSchema # [source] ModelSchema # hsml . model_schema . ModelSchema ( input_schema = None , output_schema = None ) Create a schema for a model. Arguments input_schema Optional[hsml.schema.Schema] : Schema to describe the inputs. output_schema Optional[hsml.schema.Schema] : Schema to describe the outputs. Returns ModelSchema . The model schema object. [source] to_dict # ModelSchema . to_dict () Get dict representation of the ModelSchema.","title":"Model Schema"},{"location":"generated/api/model_schema_api/#schema","text":"[source]","title":"Schema"},{"location":"generated/api/model_schema_api/#schema_1","text":"hsml . schema . Schema ( object = None ) Create a schema for a model input or output. Arguments object Optional[Union[pandas.core.frame.DataFrame, pandas.core.series.Series, pyspark.sql.dataframe.DataFrame, hsfs.training_dataset.TrainingDataset, numpy.ndarray, list]] : The object to construct the schema from. Returns Schema . The schema object. [source]","title":"Schema"},{"location":"generated/api/model_schema_api/#to_dict","text":"Schema . to_dict () Get dict representation of the Schema.","title":"to_dict"},{"location":"generated/api/model_schema_api/#modelschema","text":"[source]","title":"ModelSchema"},{"location":"generated/api/model_schema_api/#modelschema_1","text":"hsml . model_schema . ModelSchema ( input_schema = None , output_schema = None ) Create a schema for a model. Arguments input_schema Optional[hsml.schema.Schema] : Schema to describe the inputs. output_schema Optional[hsml.schema.Schema] : Schema to describe the outputs. Returns ModelSchema . The model schema object. [source]","title":"ModelSchema"},{"location":"generated/api/model_schema_api/#to_dict_1","text":"ModelSchema . to_dict () Get dict representation of the ModelSchema.","title":"to_dict"},{"location":"generated/api/predictor_config_api/","text":"Predictor Config # [source] PredictorConfig # hsml . predictor_config . PredictorConfig ( model_server , serving_tool = None , script_file = None , resources_config = None , inference_logger = None , inference_batcher = None , ) Configuration object attached to a Predictor. Properties # [source] inference_batcher # Configuration of the inference batcher attached to this predictor. [source] inference_logger # Configuration of the inference logger attached to this predictor. [source] model_server # Model server used by the predictor. [source] resources_config # Resources configuration for the predictor. [source] script_file # Script file ran by the serving component. [source] serving_tool # Serving tool used to run the model server. Methods # [source] describe # PredictorConfig . describe () [source] extract_fields_from_json # PredictorConfig . extract_fields_from_json ( json_decamelized ) [source] for_model # PredictorConfig . for_model ( model ) [source] from_json # PredictorConfig . from_json ( json_decamelized ) To be implemented by the component type [source] from_response_json # PredictorConfig . from_response_json ( json_dict ) [source] json # PredictorConfig . json () [source] to_dict # PredictorConfig . to_dict () To be implemented by the component type [source] update_from_response_json # PredictorConfig . update_from_response_json ( json_dict ) To be implemented by the component type","title":"Predictor Config"},{"location":"generated/api/predictor_config_api/#predictor-config","text":"[source]","title":"Predictor Config"},{"location":"generated/api/predictor_config_api/#predictorconfig","text":"hsml . predictor_config . PredictorConfig ( model_server , serving_tool = None , script_file = None , resources_config = None , inference_logger = None , inference_batcher = None , ) Configuration object attached to a Predictor.","title":"PredictorConfig"},{"location":"generated/api/predictor_config_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/predictor_config_api/#inference_batcher","text":"Configuration of the inference batcher attached to this predictor. [source]","title":"inference_batcher"},{"location":"generated/api/predictor_config_api/#inference_logger","text":"Configuration of the inference logger attached to this predictor. [source]","title":"inference_logger"},{"location":"generated/api/predictor_config_api/#model_server","text":"Model server used by the predictor. [source]","title":"model_server"},{"location":"generated/api/predictor_config_api/#resources_config","text":"Resources configuration for the predictor. [source]","title":"resources_config"},{"location":"generated/api/predictor_config_api/#script_file","text":"Script file ran by the serving component. [source]","title":"script_file"},{"location":"generated/api/predictor_config_api/#serving_tool","text":"Serving tool used to run the model server.","title":"serving_tool"},{"location":"generated/api/predictor_config_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/predictor_config_api/#describe","text":"PredictorConfig . describe () [source]","title":"describe"},{"location":"generated/api/predictor_config_api/#extract_fields_from_json","text":"PredictorConfig . extract_fields_from_json ( json_decamelized ) [source]","title":"extract_fields_from_json"},{"location":"generated/api/predictor_config_api/#for_model","text":"PredictorConfig . for_model ( model ) [source]","title":"for_model"},{"location":"generated/api/predictor_config_api/#from_json","text":"PredictorConfig . from_json ( json_decamelized ) To be implemented by the component type [source]","title":"from_json"},{"location":"generated/api/predictor_config_api/#from_response_json","text":"PredictorConfig . from_response_json ( json_dict ) [source]","title":"from_response_json"},{"location":"generated/api/predictor_config_api/#json","text":"PredictorConfig . json () [source]","title":"json"},{"location":"generated/api/predictor_config_api/#to_dict","text":"PredictorConfig . to_dict () To be implemented by the component type [source]","title":"to_dict"},{"location":"generated/api/predictor_config_api/#update_from_response_json","text":"PredictorConfig . update_from_response_json ( json_dict ) To be implemented by the component type","title":"update_from_response_json"},{"location":"generated/api/predictor_resources_config_api/","text":"Predictor Resources Config # [source] PredictorResourcesConfig # hsml . resources_config . PredictorResourcesConfig ( num_instances = None , cores = None , memory = None , gpus = None ) Resources configuration for predictors and transformers. Properties # [source] cores # Number of cores. [source] gpus # Number of GPUs. [source] memory # Memory resources. [source] num_instances # Number of instances. Methods # [source] describe # PredictorResourcesConfig . describe () [source] extract_fields_from_json # PredictorResourcesConfig . extract_fields_from_json ( json_decamelized ) [source] from_json # PredictorResourcesConfig . from_json ( json_decamelized ) [source] from_response_json # PredictorResourcesConfig . from_response_json ( json_dict ) [source] json # PredictorResourcesConfig . json () [source] to_dict # PredictorResourcesConfig . to_dict ()","title":"Predictor Resources Config"},{"location":"generated/api/predictor_resources_config_api/#predictor-resources-config","text":"[source]","title":"Predictor Resources Config"},{"location":"generated/api/predictor_resources_config_api/#predictorresourcesconfig","text":"hsml . resources_config . PredictorResourcesConfig ( num_instances = None , cores = None , memory = None , gpus = None ) Resources configuration for predictors and transformers.","title":"PredictorResourcesConfig"},{"location":"generated/api/predictor_resources_config_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/predictor_resources_config_api/#cores","text":"Number of cores. [source]","title":"cores"},{"location":"generated/api/predictor_resources_config_api/#gpus","text":"Number of GPUs. [source]","title":"gpus"},{"location":"generated/api/predictor_resources_config_api/#memory","text":"Memory resources. [source]","title":"memory"},{"location":"generated/api/predictor_resources_config_api/#num_instances","text":"Number of instances.","title":"num_instances"},{"location":"generated/api/predictor_resources_config_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/predictor_resources_config_api/#describe","text":"PredictorResourcesConfig . describe () [source]","title":"describe"},{"location":"generated/api/predictor_resources_config_api/#extract_fields_from_json","text":"PredictorResourcesConfig . extract_fields_from_json ( json_decamelized ) [source]","title":"extract_fields_from_json"},{"location":"generated/api/predictor_resources_config_api/#from_json","text":"PredictorResourcesConfig . from_json ( json_decamelized ) [source]","title":"from_json"},{"location":"generated/api/predictor_resources_config_api/#from_response_json","text":"PredictorResourcesConfig . from_response_json ( json_dict ) [source]","title":"from_response_json"},{"location":"generated/api/predictor_resources_config_api/#json","text":"PredictorResourcesConfig . json () [source]","title":"json"},{"location":"generated/api/predictor_resources_config_api/#to_dict","text":"PredictorResourcesConfig . to_dict ()","title":"to_dict"},{"location":"generated/api/transformer_resources_config_api/","text":"Transformer Resources Config # [source] TransformerResourcesConfig # hsml . resources_config . TransformerResourcesConfig ( num_instances = None ) Resources configuration for predictors and transformers. Properties # [source] cores # Number of cores. [source] gpus # Number of GPUs. [source] memory # Memory resources. [source] num_instances # Number of instances. Methods # [source] describe # PredictorResourcesConfig . describe () [source] extract_fields_from_json # PredictorResourcesConfig . extract_fields_from_json ( json_decamelized ) [source] from_json # PredictorResourcesConfig . from_json ( json_decamelized ) [source] from_response_json # PredictorResourcesConfig . from_response_json ( json_dict ) [source] json # PredictorResourcesConfig . json () [source] to_dict # PredictorResourcesConfig . to_dict ()","title":"Transformer Resources Config"},{"location":"generated/api/transformer_resources_config_api/#transformer-resources-config","text":"[source]","title":"Transformer Resources Config"},{"location":"generated/api/transformer_resources_config_api/#transformerresourcesconfig","text":"hsml . resources_config . TransformerResourcesConfig ( num_instances = None ) Resources configuration for predictors and transformers.","title":"TransformerResourcesConfig"},{"location":"generated/api/transformer_resources_config_api/#properties","text":"[source]","title":"Properties"},{"location":"generated/api/transformer_resources_config_api/#cores","text":"Number of cores. [source]","title":"cores"},{"location":"generated/api/transformer_resources_config_api/#gpus","text":"Number of GPUs. [source]","title":"gpus"},{"location":"generated/api/transformer_resources_config_api/#memory","text":"Memory resources. [source]","title":"memory"},{"location":"generated/api/transformer_resources_config_api/#num_instances","text":"Number of instances.","title":"num_instances"},{"location":"generated/api/transformer_resources_config_api/#methods","text":"[source]","title":"Methods"},{"location":"generated/api/transformer_resources_config_api/#describe","text":"PredictorResourcesConfig . describe () [source]","title":"describe"},{"location":"generated/api/transformer_resources_config_api/#extract_fields_from_json","text":"PredictorResourcesConfig . extract_fields_from_json ( json_decamelized ) [source]","title":"extract_fields_from_json"},{"location":"generated/api/transformer_resources_config_api/#from_json","text":"PredictorResourcesConfig . from_json ( json_decamelized ) [source]","title":"from_json"},{"location":"generated/api/transformer_resources_config_api/#from_response_json","text":"PredictorResourcesConfig . from_response_json ( json_dict ) [source]","title":"from_response_json"},{"location":"generated/api/transformer_resources_config_api/#json","text":"PredictorResourcesConfig . json () [source]","title":"json"},{"location":"generated/api/transformer_resources_config_api/#to_dict","text":"PredictorResourcesConfig . to_dict ()","title":"to_dict"},{"location":"integrations/python/","text":"Python Environments # Connecting to the Model Registry from any Python environment requires setting up a Model Registry API key and installing the library. This guide explains step by step how to connect to the Model Registry from any Python environment such as your local environment. Generate an API key # In Hopsworks, click on your username in the top-right corner and select Settings to open the user settings. Select API keys . Give the key a name and select the project, modelregistry, dataset.create, dataset.view, dataset.delete scopes before creating the key. Copy the key into your clipboard. More documentation can be found here . Create a file called modelregistry.key in your designated Python environment and save the API key from your clipboard in the file. Scopes The API key should contain at least the following scopes: project modelregistry dataset.create dataset.view dataset.delete API keys can be created in the User Settings on Hopsworks Info You are only able to retrieve the API key once. If you did not manage to copy it to your clipboard, delete it and create a new one. Install HSML # To be able to access the Hopsworks Model Registry, the HSML Python library needs to be installed in the environment from which you want to connect to the Model Registry. You can install the library through pip. We recommend using a Python environment manager such as virtualenv or conda . Matching Hopsworks version The major and minor version of HSML needs to match the major and minor version of Hopsworks . For example for a Hopsworks cluster running with version 2.5.0, the following installation command will install the latest release available for HSML. pip install hsml==2.5.* You find the Hopsworks version inside any of your Project's settings tab on Hopsworks Connect to the Model Registry # You are now ready to connect to the Hopsworks Model Registry from your Python environment: import hsml conn = hsml . connection ( host = 'my_instance' , # DNS of your Model Registry instance port = 443 , # Port to reach your Hopsworks instance, defaults to 443 project = 'my_project' , # Name of your Hopsworks Model Registry project api_key_value = 'apikey' , # The API key to authenticate with Hopsworks hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry Ports If you are unable to connect, please ensure that your Model Registry can receive incoming traffic from your Python environment on port 443. Next Steps # For more information about how to connect, see the Connection guide.","title":"Python"},{"location":"integrations/python/#python-environments","text":"Connecting to the Model Registry from any Python environment requires setting up a Model Registry API key and installing the library. This guide explains step by step how to connect to the Model Registry from any Python environment such as your local environment.","title":"Python Environments"},{"location":"integrations/python/#generate-an-api-key","text":"In Hopsworks, click on your username in the top-right corner and select Settings to open the user settings. Select API keys . Give the key a name and select the project, modelregistry, dataset.create, dataset.view, dataset.delete scopes before creating the key. Copy the key into your clipboard. More documentation can be found here . Create a file called modelregistry.key in your designated Python environment and save the API key from your clipboard in the file. Scopes The API key should contain at least the following scopes: project modelregistry dataset.create dataset.view dataset.delete API keys can be created in the User Settings on Hopsworks Info You are only able to retrieve the API key once. If you did not manage to copy it to your clipboard, delete it and create a new one.","title":"Generate an API key"},{"location":"integrations/python/#install-hsml","text":"To be able to access the Hopsworks Model Registry, the HSML Python library needs to be installed in the environment from which you want to connect to the Model Registry. You can install the library through pip. We recommend using a Python environment manager such as virtualenv or conda . Matching Hopsworks version The major and minor version of HSML needs to match the major and minor version of Hopsworks . For example for a Hopsworks cluster running with version 2.5.0, the following installation command will install the latest release available for HSML. pip install hsml==2.5.* You find the Hopsworks version inside any of your Project's settings tab on Hopsworks","title":"Install HSML"},{"location":"integrations/python/#connect-to-the-model-registry","text":"You are now ready to connect to the Hopsworks Model Registry from your Python environment: import hsml conn = hsml . connection ( host = 'my_instance' , # DNS of your Model Registry instance port = 443 , # Port to reach your Hopsworks instance, defaults to 443 project = 'my_project' , # Name of your Hopsworks Model Registry project api_key_value = 'apikey' , # The API key to authenticate with Hopsworks hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry Ports If you are unable to connect, please ensure that your Model Registry can receive incoming traffic from your Python environment on port 443.","title":"Connect to the Model Registry"},{"location":"integrations/python/#next-steps","text":"For more information about how to connect, see the Connection guide.","title":"Next Steps"},{"location":"integrations/sagemaker/","text":"AWS SageMaker Integration # Connecting to the Model Registry from SageMaker requires setting up a Model Registry API key for SageMaker and installing HSML on SageMaker. This guide explains step by step how to connect to the Model Registry from SageMaker. Generate an API key # In Hopsworks, click on your username in the top-right corner and select Settings to open the user settings. Select API keys . Give the key a name and select the project, model_registry, scopes before creating the key. Copy the key into your clipboard for the next step. Scopes The API key should contain at least the following scopes: project modelregistry dataset.create dataset.view dataset.delete API keys can be created in the User Settings on Hopsworks Info You are only ably to retrieve the API key once. If you did not manage to copy it to your clipboard, delete it again and create a new one. Quickstart API key Argument # API key as Argument To get started quickly, without saving the Hopsworks API in a secret storage, you can simply supply it as an argument when instantiating a connection: import hsml conn = hsml . connection ( host = 'my_instance' , # DNS of your Model Registry instance port = 443 , # Port to reach your Hopsworks instance, defaults to 443 project = 'my_project' , # Name of your Hopsworks Model Registry project api_key_value = 'apikey' , # The API key to authenticate with Hopsworks hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry Store the API key on AWS # The API key now needs to be stored on AWS, so it can be retrieved from within SageMaker notebooks. Identify your SageMaker role # You need to know the IAM role used by your SageMaker instance to set up the API key for it. You can find it in the overview of your SageMaker notebook instance of the AWS Management Console. In this example, the name of the role is AmazonSageMaker-ExecutionRole-20190511T072435 . The role is attached to your SageMaker notebook instance Store the API key # You have two options to make your API key accessible from SageMaker: Option 1: Using the AWS Systems Manager Parameter Store # Store the API key in the AWS Systems Manager Parameter Store # In the AWS Management Console, ensure that your active region is the region you use for SageMaker. Go to the AWS Systems Manager choose Parameter Store in the left navigation bar and select Create Parameter . As name, enter /hopsworks/role/[MY_SAGEMAKER_ROLE]/type/api-key replacing [MY_SAGEMAKER_ROLE] with the AWS role used by the SageMaker instance that should access the Model Registry. Select Secure String as type and create the parameter . Store the API key in the AWS Systems Manager Parameter Store Grant access to the Parameter Store from the SageMaker notebook role # In the AWS Management Console, go to IAM , select Roles and then the role that is used when creating SageMaker notebook instances. Select Add inline policy . Choose Systems Manager as service, expand the Read access level and check GetParameter . Expand Resources and select Add ARN . Enter the region of the Systems Manager as well as the name of the parameter WITHOUT the leading slash e.g. hopsworks/role/[MY_SAGEMAKER_ROLE]/type/api-key and click Add . Click on Review , give the policy a name und click on Create policy . Grant access to the Parameter Store from the SageMaker notebook role Option 2: Using the AWS Secrets Manager # Store the API key in the AWS Secrets Manager # In the AWS Management Console, ensure that your active region is the region you use for SageMaker. Go to the AWS Secrets Manager and select Store new secret . Select Other type of secrets and add api-key as the key and paste the API key created in the previous step as the value. Click next. Store the API key in the AWS Secrets Manager As secret name, enter hopsworks/role/[MY_SAGEMAKER_ROLE] replacing [MY_SAGEMAKER_ROLE] with the AWS role used by the SageMaker instance that should access the Model Registry. Select next twice and finally store the secret. Then click on the secret in the secrets list and take note of the Secret ARN . Store the API key in the AWS Secrets Manager Grant access to the SecretsManager to the SageMaker notebook role # In the AWS Management Console, go to IAM , select Roles and then the role that is used when creating SageMaker notebook instances. Select Add inline policy . Choose Secrets Manager as service, expand the Read access level and check GetSecretValue . Expand Resources and select Add ARN . Paste the ARN of the secret created in the previous step. Click on Review , give the policy a name und click on Create policy . Grant access to the SecretsManager to the SageMaker notebook role Install HSML # To be able to access the Hopsworks Model Registry, the HSML Python library needs to be installed. One way of achieving this is by opening a Python notebook in SageMaker and installing the HSML with a magic command and pip: Matching Hopsworks version The major and minor version of HSML needs to match the major and minor version of Hopsworks . For example for a Hopsworks cluster running with version 2.5.0, the following installation command will install the latest release available for HSML. pip install hsml==2.5.* You find the Hopsworks version inside any of your Project's settings tab on Hopsworks Note that the library will not be persistent. For information around how to permanently install a library to SageMaker, see Install External Libraries and Kernels in Notebook Instances. Connect to the Model Registry Store # You are now ready to connect to the Hopsworks Model Registry from SageMaker: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project secrets_store = 'secretsmanager' , # Either parameterstore or secretsmanager hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry Ports If you have trouble connecting, please ensure that the Security Group of your Hopsworks instance on AWS is configured to allow incoming traffic from your SageMaker instance on port 443. See VPC Security Groups for more information. If your SageMaker instances are not in the same VPC as your Hopsworks instance and the Hopsworks instance is not accessible from the internet then you will need to configure VPC Peering on AWS . Next Steps # For more information about how to use the Model Registry, see the Quickstart Guide .","title":"AWS Sagemaker"},{"location":"integrations/sagemaker/#aws-sagemaker-integration","text":"Connecting to the Model Registry from SageMaker requires setting up a Model Registry API key for SageMaker and installing HSML on SageMaker. This guide explains step by step how to connect to the Model Registry from SageMaker.","title":"AWS SageMaker Integration"},{"location":"integrations/sagemaker/#generate-an-api-key","text":"In Hopsworks, click on your username in the top-right corner and select Settings to open the user settings. Select API keys . Give the key a name and select the project, model_registry, scopes before creating the key. Copy the key into your clipboard for the next step. Scopes The API key should contain at least the following scopes: project modelregistry dataset.create dataset.view dataset.delete API keys can be created in the User Settings on Hopsworks Info You are only ably to retrieve the API key once. If you did not manage to copy it to your clipboard, delete it again and create a new one.","title":"Generate an API key"},{"location":"integrations/sagemaker/#quickstart-api-key-argument","text":"API key as Argument To get started quickly, without saving the Hopsworks API in a secret storage, you can simply supply it as an argument when instantiating a connection: import hsml conn = hsml . connection ( host = 'my_instance' , # DNS of your Model Registry instance port = 443 , # Port to reach your Hopsworks instance, defaults to 443 project = 'my_project' , # Name of your Hopsworks Model Registry project api_key_value = 'apikey' , # The API key to authenticate with Hopsworks hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry","title":"Quickstart API key Argument"},{"location":"integrations/sagemaker/#store-the-api-key-on-aws","text":"The API key now needs to be stored on AWS, so it can be retrieved from within SageMaker notebooks.","title":"Store the API key on AWS"},{"location":"integrations/sagemaker/#identify-your-sagemaker-role","text":"You need to know the IAM role used by your SageMaker instance to set up the API key for it. You can find it in the overview of your SageMaker notebook instance of the AWS Management Console. In this example, the name of the role is AmazonSageMaker-ExecutionRole-20190511T072435 . The role is attached to your SageMaker notebook instance","title":"Identify your SageMaker role"},{"location":"integrations/sagemaker/#store-the-api-key","text":"You have two options to make your API key accessible from SageMaker:","title":"Store the API key"},{"location":"integrations/sagemaker/#option-1-using-the-aws-systems-manager-parameter-store","text":"","title":"Option 1: Using the AWS Systems Manager Parameter Store"},{"location":"integrations/sagemaker/#store-the-api-key-in-the-aws-systems-manager-parameter-store","text":"In the AWS Management Console, ensure that your active region is the region you use for SageMaker. Go to the AWS Systems Manager choose Parameter Store in the left navigation bar and select Create Parameter . As name, enter /hopsworks/role/[MY_SAGEMAKER_ROLE]/type/api-key replacing [MY_SAGEMAKER_ROLE] with the AWS role used by the SageMaker instance that should access the Model Registry. Select Secure String as type and create the parameter . Store the API key in the AWS Systems Manager Parameter Store","title":"Store the API key in the AWS Systems Manager Parameter Store"},{"location":"integrations/sagemaker/#grant-access-to-the-parameter-store-from-the-sagemaker-notebook-role","text":"In the AWS Management Console, go to IAM , select Roles and then the role that is used when creating SageMaker notebook instances. Select Add inline policy . Choose Systems Manager as service, expand the Read access level and check GetParameter . Expand Resources and select Add ARN . Enter the region of the Systems Manager as well as the name of the parameter WITHOUT the leading slash e.g. hopsworks/role/[MY_SAGEMAKER_ROLE]/type/api-key and click Add . Click on Review , give the policy a name und click on Create policy . Grant access to the Parameter Store from the SageMaker notebook role","title":"Grant access to the Parameter Store from the SageMaker notebook role"},{"location":"integrations/sagemaker/#option-2-using-the-aws-secrets-manager","text":"","title":"Option 2: Using the AWS Secrets Manager"},{"location":"integrations/sagemaker/#store-the-api-key-in-the-aws-secrets-manager","text":"In the AWS Management Console, ensure that your active region is the region you use for SageMaker. Go to the AWS Secrets Manager and select Store new secret . Select Other type of secrets and add api-key as the key and paste the API key created in the previous step as the value. Click next. Store the API key in the AWS Secrets Manager As secret name, enter hopsworks/role/[MY_SAGEMAKER_ROLE] replacing [MY_SAGEMAKER_ROLE] with the AWS role used by the SageMaker instance that should access the Model Registry. Select next twice and finally store the secret. Then click on the secret in the secrets list and take note of the Secret ARN . Store the API key in the AWS Secrets Manager","title":"Store the API key in the AWS Secrets Manager"},{"location":"integrations/sagemaker/#grant-access-to-the-secretsmanager-to-the-sagemaker-notebook-role","text":"In the AWS Management Console, go to IAM , select Roles and then the role that is used when creating SageMaker notebook instances. Select Add inline policy . Choose Secrets Manager as service, expand the Read access level and check GetSecretValue . Expand Resources and select Add ARN . Paste the ARN of the secret created in the previous step. Click on Review , give the policy a name und click on Create policy . Grant access to the SecretsManager to the SageMaker notebook role","title":"Grant access to the SecretsManager to the SageMaker notebook role"},{"location":"integrations/sagemaker/#install-hsml","text":"To be able to access the Hopsworks Model Registry, the HSML Python library needs to be installed. One way of achieving this is by opening a Python notebook in SageMaker and installing the HSML with a magic command and pip: Matching Hopsworks version The major and minor version of HSML needs to match the major and minor version of Hopsworks . For example for a Hopsworks cluster running with version 2.5.0, the following installation command will install the latest release available for HSML. pip install hsml==2.5.* You find the Hopsworks version inside any of your Project's settings tab on Hopsworks Note that the library will not be persistent. For information around how to permanently install a library to SageMaker, see Install External Libraries and Kernels in Notebook Instances.","title":"Install HSML"},{"location":"integrations/sagemaker/#connect-to-the-model-registry-store","text":"You are now ready to connect to the Hopsworks Model Registry from SageMaker: import hsml conn = hsml . connection ( 'my_instance' , # DNS of your Model Registry instance 443 , # Port to reach your Hopsworks instance, defaults to 443 'my_project' , # Name of your Hopsworks Model Registry project secrets_store = 'secretsmanager' , # Either parameterstore or secretsmanager hostname_verification = True # Disable for self-signed certificates ) mr = conn . get_model_registry () # Get the project's default model registry Ports If you have trouble connecting, please ensure that the Security Group of your Hopsworks instance on AWS is configured to allow incoming traffic from your SageMaker instance on port 443. See VPC Security Groups for more information. If your SageMaker instances are not in the same VPC as your Hopsworks instance and the Hopsworks instance is not accessible from the internet then you will need to configure VPC Peering on AWS .","title":"Connect to the Model Registry Store"},{"location":"integrations/sagemaker/#next-steps","text":"For more information about how to use the Model Registry, see the Quickstart Guide .","title":"Next Steps"}]}